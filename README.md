
# Tech Challenge - FIAP (Fase 2)

## üéØ Desafio
Desenvolver um sistema baseado em Algoritmo Gen√©tico para otimizar a arquitetura de uma **Rede Neural Artificial**, com o objetivo de maximizar a acur√°cia em um problema de classifica√ß√£o.

---

## üß™ Problema Escolhido
**Otimizar a estrutura de uma rede neural para o dataset Iris.**

Cada indiv√≠duo da popula√ß√£o representa uma configura√ß√£o de rede com:
- N√∫mero de neur√¥nios na primeira camada oculta
- N√∫mero de neur√¥nios na segunda camada oculta
- Fun√ß√£o de ativa√ß√£o da camada 1
- Fun√ß√£o de ativa√ß√£o da camada 2

Exemplo de gene:
```python
[32, 16, 0, 1]  # 32 neur√¥nios + ReLU, depois 16 neur√¥nios + Sigmoid
```

As ativa√ß√µes poss√≠veis s√£o:
- 0 = relu
- 1 = sigmoid
- 2 = tanh

---

## ‚öôÔ∏è Implementa√ß√£o

- **Linguagem**: Python
- **Bibliotecas**: `tensorflow.keras`, `sklearn`, `numpy`, `random`
- **Fitness**: acur√°cia da rede neural treinada por 30 √©pocas
- **Dataset**: Iris (sklearn.datasets)
- **GA**: Sele√ß√£o dos melhores, crossover e muta√ß√£o

---

## üìà An√°lise dos Resultados

O algoritmo gen√©tico conseguiu encontrar boas configura√ß√µes de rede em poucas gera√ß√µes.  
Em geral, as melhores redes possu√≠am:
- Camadas ocultas com 16 a 48 neur√¥nios
- Fun√ß√µes de ativa√ß√£o ReLU ou combina√ß√£o ReLU + Sigmoid

A acur√°cia final m√©dia das melhores redes ficou entre **95% e 98%**, superando configura√ß√µes manuais simples.  
As configura√ß√µes eram avaliadas automaticamente, e a sele√ß√£o natural foi eficiente para otimizar a rede sem interven√ß√£o manual.

---

## üß† Conclus√£o Cr√≠tica

Este projeto mostrou que **algoritmos gen√©ticos s√£o eficazes para otimiza√ß√£o de arquitetura de redes neurais** em problemas simples como o Iris.  
Apesar da simplicidade do dataset, o processo evolutivo √© facilmente adapt√°vel para bases maiores.

### Pontos fortes:
- Automatiza√ß√£o da escolha de hiperpar√¢metros
- Resultados concretos e interpret√°veis
- C√≥digo reutiliz√°vel para outros datasets

### Limita√ß√µes:
- Tempo de execu√ß√£o cresce com o n√∫mero de √©pocas e tamanho da popula√ß√£o
- A solu√ß√£o pode ser sens√≠vel a valores iniciais e aleatoriedade

Este tipo de abordagem pode ser √∫til em cen√°rios reais onde **n√£o √© vi√°vel testar manualmente dezenas de combina√ß√µes**.  
Mesmo com redes simples, o GA se mostrou uma ferramenta poderosa para aprender boas estruturas.

---

## üìÅ Entreg√°veis
- C√≥digo-fonte (notebook)
- V√≠deo com demonstra√ß√£o no YouTube
- Este README explicando o projeto

---

## üë§ Autor
**Lu√≠s Felipe Alves Silva**  
RM: 363734  
P√≥s-gradua√ß√£o em Intelig√™ncia Artificial para Devs ‚Äì FIAP
